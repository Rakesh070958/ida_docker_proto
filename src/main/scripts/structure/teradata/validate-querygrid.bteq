bteq << EOF

/*
 * Validate-querygrid: Script for validating the server object - QueryGrid
 * author: Ana - Maria MUSAT
 */

.LOGON $servername/$superuser,$superuser_password;

.set width 300;
.set errorout stdout;


/*
* Create the users and grant the different profiles to them.
*/
CREATE USER $user_db_name_restricted FROM $env_usr AS
  PASSWORD = pass_1234,
  PERMANENT = 0,
  ACCOUNT = '$M0+$user_db_name_restricted&S&D&H$',
  PROFILE = $profile_env,
  DEFAULT ROLE = ALL,
  DEFAULT DATABASE = $landlord_tenant;

/*
* Modify the password -
* this ensures that it won't be necessary to change the password at the first login
*/

MODIFY USER $user_db_name_restricted AS PASSWORD = pass_1234;

CREATE ROLE $ro_db_name_restricted;
GRANT SELECT ON $db_name.$view_db_qg_restricted TO $ro_db_name_restricted;
GRANT $ro_db_name_restricted TO $user_db_name_restricted;

GRANT $ro_db_name_restricted TO $user_db_name;
GRANT SELECT ON $db_name.$view_db_qg TO $user_db_name;


.LOGOFF;


.LOGON $servername/$user_db_name_restricted,pass_1234;

.set width 200;
.set errorout stdout;

/* Should work */
SELECT COUNT(*) FROM $db_name.$view_db_qg_restricted;
/* Should fail */
SELECT COUNT(*) FROM $db_name.$view_db_qg;

/* Create server object -> Should Fail */
CREATE FOREIGN SERVER TD_SERVER_DB.SO_TEST_QG USING
        hosttype ('$hosttype')
        server('$hive_metastore_server') /* hive metastore */
        port('$hive_metastore_port') /* hive metastore port */
        hiveport('$hive_port') /* Hive Server 2 port */
        username ('$hive_username') /* the user impersonated by tduser */
		dbname('$(echo "${landlord}_${tenant}_${environment}_d_mtd" | tr '[:upper:]' '[:lower:]')') /* the hive database to be used */
    templeton_port('$hive_templeton_port') /* WebHCatalog port */
DO IMPORT WITH SYSLIB.LOAD_FROM_HCATALOG USING
        transformformatting ('true')
        hadoop_properties('<dfs.client.use.datanode.hostname=true>,<dfs.datanode.use.datanode.hostname=true>,<dfs.nameservices=$hadoop_nameservices>,<dfs.ha.namenodes.$hadoop_nameservices=nn1,nn2>,<dfs.namenode.rpc-address.$hadoop_nameservices.nn1=$hadoop_namenode1>,<dfs.namenode.rpc-address.$hadoop_nameservices.nn2=$hadoop_namenode2>,<dfs.client.failover.proxy.provider.$hadoop_nameservices=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider>'), /* HA config if any */
DO EXPORT WITH SYSLIB.LOAD_TO_HCATALOG USING
        merge_hdfs_files('true')
        hadoop_properties('<dfs.client.use.datanode.hostname=true>,<dfs.datanode.use.datanode.hostname=true>,<dfs.nameservices=$hadoop_nameservices>,<dfs.ha.namenodes.$hadoop_nameservices=nn1,nn2>,<dfs.namenode.rpc-address.$hadoop_nameservices.nn1=$hadoop_namenode1>,<dfs.namenode.rpc-address.$hadoop_nameservices.nn2=$hadoop_namenode2>,<dfs.client.failover.proxy.provider.$hadoop_nameservices=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider>');

/*Select from Hive table -> Should fail*/
select count(*) from $(echo "${landlord}_${tenant}_${environment}_d_mtd" | tr '[:upper:]' '[:lower:]').audit@$server_object_db;
select count(*) from $(echo "${landlord}_${tenant}_${environment}_d_mtd" | tr '[:upper:]' '[:lower:]').$table_db_qg@$server_object_db;

.LOGOFF;

.LOGON $servername/$user_db_name,pass_1234;

.set width 200;
.set errorout stdout;

/* Should work */
SELECT COUNT(*) FROM $db_name.$view_db_qg_restricted;
/* Should work */
SELECT COUNT(*) FROM $db_name.$view_db_qg;

/* Create server object -> Should Fail */
CREATE FOREIGN SERVER TD_SERVER_DB.SO_TEST_QG USING
	hosttype ('$hosttype') 
	server('$hive_metastore_server') /* hive metastore */
	port('$hive_metastore_port') /* hive metastore port */
	hiveport('$hive_port') /* Hive Server 2 port */
	username ('$hive_username') /* the user impersonated by tduser */
    dbname('$(echo "${landlord}_${tenant}_${environment}_d_mtd" | tr '[:upper:]' '[:lower:]')') /* the hive database to be used */
    templeton_port('$hive_templeton_port') /* WebHCatalog port */
DO IMPORT WITH SYSLIB.LOAD_FROM_HCATALOG USING
	transformformatting ('true')
	hadoop_properties('<dfs.client.use.datanode.hostname=true>,<dfs.datanode.use.datanode.hostname=true>,<dfs.nameservices=$hadoop_nameservices>,<dfs.ha.namenodes.$hadoop_nameservices=nn1,nn2>,<dfs.namenode.rpc-address.$hadoop_nameservices.nn1=$hadoop_namenode1>,<dfs.namenode.rpc-address.$hadoop_nameservices.nn2=$hadoop_namenode2>,<dfs.client.failover.proxy.provider.$hadoop_nameservices=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider>'), /* HA config if any */
DO EXPORT WITH SYSLIB.LOAD_TO_HCATALOG USING
	merge_hdfs_files('true')
	hadoop_properties('<dfs.client.use.datanode.hostname=true>,<dfs.datanode.use.datanode.hostname=true>,<dfs.nameservices=$hadoop_nameservices>,<dfs.ha.namenodes.$hadoop_nameservices=nn1,nn2>,<dfs.namenode.rpc-address.$hadoop_nameservices.nn1=$hadoop_namenode1>,<dfs.namenode.rpc-address.$hadoop_nameservices.nn2=$hadoop_namenode2>,<dfs.client.failover.proxy.provider.$hadoop_nameservices=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider>');

/*Select from Hive table -> Should fail*/

select count(*) from $(echo "${landlord}_${tenant}_${environment}_d_mtd" | tr '[:upper:]' '[:lower:]').audit@$server_object_db;
select count(*) from $(echo "${landlord}_${tenant}_${environment}_d_mtd" | tr '[:upper:]' '[:lower:]').table_db_qg@$server_object_db;

SELECT * FROM FOREIGN TABLE (select * from $(echo "${landlord}_${tenant}_${environment}_d_mtd" | tr '[:upper:]' '[:lower:]').audit)@$server_object_db as dt;

.LOGOFF;

.QUIT;
EOF
